{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 1 Recommender Systems Naive Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task was to create recommender systems using the 1M dataset from Movielens. We implemented four naive approaches and matrix facotrization.\n",
    "\n",
    "We implemented, in Python, several recommendation algorithms and estimate their accuracy with the Root Mean Squared Error (RMSE), and the Mean  Absolute  Error (MAE).  In addition, to  make  sure  that  your  results  are  reliable  use  5-fold  cross-validation.  The average error of these five models (measured on the 5 test sets) \n",
    "is a reliable estimate of the accuracy of the (hypothetical) final model that is trained on the whole data set. 5-fold cross-validation is described in  more detail later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "The data contains 1,000,209 anonymous ratings of approximately 3,900 movies \n",
    "made by 6,040 MovieLens users who joined MovieLens in 2000.\n",
    "format is UserID::MovieID::Rating::Timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ratings = pd.read_csv('ratings.dat')\n",
    "\n",
    "ratings = np.loadtxt('ratings.dat', delimiter=\"::\")\n",
    "\n",
    "#format is UserID::MovieID::Rating::Timestamp\n",
    "users = np.unique(ratings[:,0])\n",
    "items = np.unique(ratings[:,1])\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We first use four naive approaches to predict the rating a particular user will give a movie. Using the four equations from the slides from class\n",
    "\n",
    "Global Average: Is very simplistic approach, it takes the average over all (user, item) pairs.\n",
    "\\begin{equation*}\n",
    "R_{global}(User, Item) = mean(all\\;ratings)\n",
    "\\end{equation*}\n",
    "Average over an Item: Takes the average over all (user, item) pairs but only for one item.\n",
    "\\begin{equation*}\n",
    "R_{item}(User, Item) = mean(all\\;ratings\\;for\\;Item)\n",
    "\\end{equation*}\n",
    "Average over an User: Takes the average over all (user, item) pairs but only for one user.\n",
    "\\begin{equation*}\n",
    "R_{user}(User, Item) = mean(all\\;ratings\\;for\\;User)\n",
    "\\end{equation*}\n",
    "Linear Regression: This approaches combines the user and item means to create a better prediction. It assigns different weights for both the user and the item mean to account for uneven significance between them. We will call these weight $\\alpha$ and $\\beta$. Then accounts for some overarching bias that we will detect using the global average and account for it in $\\gamma$. Estimate the parameters $\\alpha$, $\\beta$, $\\gamma$ with linear regression. We are trying to approximate the rating column as a linear combination of the other two columns, users and item and a constant $\\gamma$\n",
    "\n",
    "\\begin{equation*}\n",
    "R_{user-item}(User, Item) = \\alpha * R_{user}(User, Item) + \\beta * R_{item} + \\gamma\n",
    "\\end{equation*}\n",
    "\n",
    "We create seperate functions for each of the first three approaches and incoporated the linear regression later in the code for ease.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def item_avg(ratings,item):\n",
    "    \"\"\"The mean of all ratings of an item. This could work \n",
    "    well in the sense that if an users rate particular \n",
    "    item generally the same\n",
    "    Input: The array of data with the ratings\"\"\"\n",
    "    \n",
    "    i_ratings = ratings[ratings[:,1] == item]\n",
    "    R_item = np.mean(i_ratings[:,2])\n",
    "    \n",
    "    return R_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def global_avg(ratings):\n",
    "    \n",
    "    \"\"\"Mean over all ratings from all users. Not expecting \n",
    "    a accurate prediction but is the simpliest approach.\n",
    "    Input: The array of data with the ratings\"\"\"\n",
    "    \n",
    "    R_global = np.mean(ratings[:,2])\n",
    "    \n",
    "    return R_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_avg(ratings,user):\n",
    "    \n",
    "    \"\"\"Find mean of all ratings of a user. This method works better\n",
    "    for users who rate many items rather then a few.\n",
    "    Input: ratings array and user number\"\"\"\n",
    "    \n",
    "    u_ratings = ratings[ratings[:,0] == user]\n",
    "    R_user = np.mean(u_ratings[:,2])\n",
    "    \n",
    "    return R_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Five Fold Cross-Validation\n",
    "\n",
    "First we defined memory to store the results.\n",
    "We defined functions to calculate the errors on for our different approaches (mean_err()) and (global_err()).\n",
    "Then we use the modulo operator to split the data into five equal folds and np.random to shuffle each sequence of data.\n",
    "Four folds will make up the training data and one fold will be the test set.\n",
    "The training set we use to train the algorithm and to predict new ratings for users\n",
    "The test set is what we apply our trained algorithm to and find our accuracy.\n",
    "We iterate through the procedure five times so that every set has been the test set one time.\n",
    "The we treat the test set as new ratings provided by the users.\n",
    "Then we calculate the accuracy by taking the mean over the five iterations.\n",
    "We calculate the accuracy using the RMSE and the MAE.\n",
    "We account for gaps in the data with a conditional where we check for a rating and if there is no rating use the global mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime:  271.8847801685333 seconds ---\n",
      "Train results:\n",
      "User mean RMSE: 0.82896757447\n",
      "User mean MAE: 0.822737078586\n",
      "Item mean RMSE: 0.78240409533\n",
      "Item mean MAE: 0.778338232748\n",
      "Global mean RMSE: 1.11710112744\n",
      "Global mean MAE: 0.933860752823\n",
      "\n",
      "\n",
      "Test results:\n",
      "User mean RMSE: 1.03549268243\n",
      "User mean MAE: 1.02767187417\n",
      "Item mean RMSE: 0.979458646244\n",
      "Item mean MAE: 0.974217433147\n",
      "Global mean RMSE: 1.11710198981\n",
      "Global mean MAE: 0.93386130485\n",
      "\n",
      "\n",
      "Linear Regression results:\n",
      "alpha: 0.7818509582241939\n",
      "beta: 0.8748595533670936\n",
      "gamma: -2.3520510519663214\n",
      "Train set:\n",
      "RMSE: 0.91462036644\n",
      "MAE: 0.836530516689\n",
      "Test set:\n",
      "RMSE: 0.924407363516\n",
      "MAE: 0.854531144446\n"
     ]
    }
   ],
   "source": [
    "def five_fold_CV(ratings):\n",
    "    \n",
    "    \"\"\"\n",
    "    Test the models with 5 fold cross validation\n",
    "    Input: ratings \n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(17) # For reproducibility\n",
    "\n",
    "    # split data into 5 train and test folds\n",
    "    folds=5\n",
    "\n",
    "    # allocate memory for results:\n",
    "    error_train_R_user_RSME = np.zeros(folds)\n",
    "    error_train_R_user_MAE = np.zeros(folds)\n",
    "    error_train_R_item_RSME = np.zeros(folds)\n",
    "    error_train_R_item_MAE = np.zeros(folds)\n",
    "    error_train_R_global_RSME = np.zeros(folds)\n",
    "    error_train_R_global_MAE = np.zeros(folds)\n",
    "    error_train_LR_RSME = np.zeros(folds)\n",
    "    error_train_LR_MAE = np.zeros(folds)\n",
    "    error_test_R_user_RSME = np.zeros(folds)\n",
    "    error_test_R_user_MAE = np.zeros(folds)\n",
    "    error_test_R_item_RSME = np.zeros(folds)\n",
    "    error_test_R_item_MAE = np.zeros(folds)\n",
    "    error_test_R_global_RSME = np.zeros(folds)\n",
    "    error_test_R_global_MAE = np.zeros(folds)\n",
    "    error_test_LR_RSME = np.zeros(folds) \n",
    "    error_test_LR_MAE = np.zeros(folds) \n",
    "  \n",
    "    \n",
    "    alpha = np.zeros(folds)\n",
    "    beta = np.zeros(folds)\n",
    "    gamma = np.zeros(folds)\n",
    "\n",
    "    seqs = [x%folds for x in range(len(ratings))]\n",
    "    np.random.shuffle(seqs) \n",
    "    \n",
    "    \n",
    "    #Define the functions to calculate the errors later\n",
    "    def mean_err(test, test_predict_R, train, train_predict_R):\n",
    "        \n",
    "        \"\"\"\n",
    "        Error for the mean rating of a user and a item\n",
    "        Mean Absolute Error mean(|value - expected value|)\n",
    "        Inputs: Test, test predictions for item or user, Train, train predictions for user or item\n",
    "        RMSE Error on the  sqrt(1/n(sum(predicted - true)^2)))\n",
    "        \"\"\"\n",
    "        error_test_R_MAE = np.mean(np.abs(test[:,2] - test_predict_R[:,1]))\n",
    "        error_train_R_MAE = np.mean(np.abs(train[:,2] - train_predict_R[:,1]))\n",
    "        \n",
    "        #Use np.power in order to brodacasting two arrays \n",
    "        error_test_RSME = np.sqrt(np.mean(np.power(test[:,2] - test_predict_R[:,1],2)))\n",
    "        error_train_RSME = np.sqrt(np.mean(np.power(train[:,2] - train_predict_R[:,1],2)))\n",
    "        \n",
    "        return error_test_RSME, error_train_RSME, error_test_R_MAE, error_train_R_MAE\n",
    "        \n",
    "    def global_mean_err():\n",
    "        \n",
    "        \"\"\"\n",
    "        Error for the global mean rating\n",
    "        Error on the  sqrt(mean(value -  expected value)^2)\n",
    "        Mean Absolute Error mean(|value - expected value|)\n",
    "        \"\"\"\n",
    "        \n",
    "        error_test_R_global_RSME[fold] = np.sqrt(np.mean((test[:,2] - global_mean_train)**2))\n",
    "        error_test_R_global_MAE[fold] = np.mean(np.abs(test[:,2] - global_mean_train))\n",
    "        error_train_R_global_RSME[fold] = np.sqrt(np.mean((train[:,2] - global_mean_train)**2))\n",
    "        error_train_R_global_MAE[fold] = np.mean(np.abs(train[:,2] - global_mean_train))\n",
    "        \n",
    "\n",
    "    def linear_regression(train):\n",
    "        \"\"\"\n",
    "        This function performs the linear regression\n",
    "        Inputs: The training data\n",
    "        \"\"\"\n",
    "        y = train[:,2]\n",
    "        \n",
    "        # make the x_1,x_2 matrices\n",
    "        x_1 = train_predict_R_user[:,1]\n",
    "        x_2 = train_predict_R_item[:,1]\n",
    "        \n",
    "        #Section taken from sklearn.linear_model.LinearRegression\n",
    "        #http://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares\n",
    "        X = np.asarray([x_1,x_2]).T\n",
    "        reg = linear_model.LinearRegression()\n",
    "        reg.fit(X,y)\n",
    "        alpha, beta = reg.coef_\n",
    "        gamma = reg.intercept_\n",
    "\n",
    "        return alpha,beta,gamma\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #for each fold:\n",
    "    for fold in range(folds):\n",
    "\n",
    "        train_chunk = np.array([x!=fold for x in seqs])\n",
    "        test_chunk = np.array([x==fold for x in seqs])\n",
    "        train = ratings[train_chunk]\n",
    "        test = ratings[test_chunk]\n",
    "\n",
    "        # A 200042x2 matrix that holds all test/train users/items and their prediction ratings\n",
    "        test_predict_R_user = np.array([test[:,0],np.empty(len(test[:,0]))]).T\n",
    "        test_predict_R_item = np.array([test[:,1],np.empty(len(test[:,1]))]).T\n",
    "        train_predict_R_user = np.array([train[:,0],np.empty(len(train[:,0]))]).T\n",
    "        train_predict_R_item = np.array([train[:,1],np.empty(len(train[:,1]))]).T\n",
    "\n",
    "        global_mean_train = global_avg(train)\n",
    "        \n",
    "        training_itms = np.unique(train[:,1]) \n",
    "        training_usrs = np.unique(train[:,0]) \n",
    "        \n",
    "        for user in users:\n",
    "            \n",
    "            if user in training_usrs:\n",
    "                \n",
    "                # user and item mean on the train set\n",
    "                single_user_mean = user_avg(train,user) \n",
    "                \n",
    "                # make a matrix with test predictions for calculation of error\n",
    "                test_predict_R_user[test_predict_R_user[:,0] == user, 1] = single_user_mean\n",
    "                train_predict_R_user[train_predict_R_user[:,0] == user, 1] = single_user_mean\n",
    "                \n",
    "            else: \n",
    "                \n",
    "                # use the global mean is there is no user rating\n",
    "                test_predict_R_user[test_predict_R_user[:,0] == user, 1] = global_mean_train\n",
    "                \n",
    "        for item in items:\n",
    "            \n",
    "            if item in training_itms: \n",
    "                \n",
    "                single_item_mean = item_avg(train,item)\n",
    "                \n",
    "                # make a matrix with test predictions for the error calculation \n",
    "                test_predict_R_item[test_predict_R_item[:,0] == item, 1] = single_item_mean\n",
    "                train_predict_R_item[train_predict_R_item[:,0] == item, 1] = single_item_mean\n",
    "                \n",
    "            else: \n",
    "                # use the global mean if there is no item rating\n",
    "                test_predict_R_item[test_predict_R_item[:,0] == item, 1] = global_mean_train\n",
    "\n",
    "        # Calculate the test and train RSME and MAE for item and user means by using mean_err() \n",
    "        error_test_R_user_RSME[fold], error_test_R_user_MAE[fold], error_train_R_user_RSME[fold], error_train_R_user_MAE[fold] = \\\n",
    "        mean_err(test, test_predict_R_user, train, train_predict_R_user)\n",
    "        \n",
    "        error_test_R_item_RSME[fold], error_test_R_item_MAE[fold], error_train_R_item_RSME[fold], error_train_R_item_MAE[fold] = \\\n",
    "        mean_err(test, test_predict_R_item, train, train_predict_R_item)\n",
    "        \n",
    "        # Calculate the errors RSME and MAE using global_mean_err()\n",
    "        global_mean_err()\n",
    "\n",
    "        #The Linear Regression\n",
    "        alpha[fold], beta[fold], gamma[fold] = linear_regression(train)\n",
    "        LR_predict_train = alpha[fold] * train_predict_R_user[:,1] + beta[fold] * train_predict_R_item[:,1] + gamma[fold]\n",
    "        LR_predict_test = alpha[fold] * test_predict_R_user[:,1] + beta[fold] * test_predict_R_item[:,1] + gamma[fold]\n",
    "        \n",
    "        #We are trying to minimize the RMSE\n",
    "        error_train_LR_RSME[fold] = np.sqrt(np.mean((train[:,2] - LR_predict_train)**2))\n",
    "        error_test_LR_RSME[fold] = np.sqrt(np.mean((test[:,2] - LR_predict_test )**2))\n",
    "\n",
    "        error_train_LR_MAE[fold] = np.mean(np.abs((train[:,2] - LR_predict_train)**2))\n",
    "        error_test_LR_MAE[fold] = np.mean(np.abs((test[:,2] - LR_predict_test )**2))\n",
    "    \n",
    "    #Results\n",
    "    print(\"Total runtime:  %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    print('Train results:')\n",
    "    print('User mean RMSE: %s'%np.mean(error_train_R_user_RSME))\n",
    "    print('User mean MAE: %s'%np.mean(error_train_R_user_MAE))\n",
    "    print('Item mean RMSE: %s'%np.mean(error_train_R_item_RSME))\n",
    "    print('Item mean MAE: %s'%np.mean(error_train_R_item_MAE))\n",
    "    print('Global mean RMSE: %s'%np.mean(error_train_R_global_RSME))\n",
    "    print('Global mean MAE: %s'%np.mean(error_train_R_global_MAE))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "    print('Test results:')\n",
    "    print('User mean RMSE: %s'%np.mean(error_test_R_user_RSME))\n",
    "    print('User mean MAE: %s'%np.mean(error_test_R_user_MAE))\n",
    "    print('Item mean RMSE: %s'%np.mean(error_test_R_item_RSME))\n",
    "    print('Item mean MAE: %s'%np.mean(error_test_R_item_MAE))\n",
    "    print('Global mean RMSE: %s'%np.mean(error_test_R_global_RSME))\n",
    "    print('Global mean MAE: %s'%np.mean(error_test_R_global_MAE))\n",
    "    print('\\n')\n",
    "\n",
    "    print('Linear Regression results:')\n",
    "    print('alpha: {}'.format(np.mean(alpha)))\n",
    "    print('beta: {}'.format(np.mean(beta)))\n",
    "    print('gamma: {}'.format(np.mean(gamma)))\n",
    "    print('Train set:')\n",
    "    print('RMSE: %s'%np.mean(error_train_LR_RSME))\n",
    "    print('MAE: %s'%np.mean(error_train_LR_MAE))\n",
    "    print('Test set:')\n",
    "    print('RMSE: %s'%np.mean(error_test_LR_RSME))\n",
    "    print('MAE: %s'%np.mean(error_test_LR_MAE))\n",
    "    \n",
    "\n",
    "five_fold_CV(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Results were as follows\n",
    "Total runtime:  313.4345362186432 seconds or about 5 minutes\n",
    "Train results:\n",
    "User mean RMSE:...... 0.82896757447\n",
    "User mean MAE: ...... 0.822737078586\n",
    "Item mean RMSE:...... 0.78240409533\n",
    "Item mean MAE: ...... 0.778338232748\n",
    "Global mean RMSE:.... 1.11710112744\n",
    "Global mean MAE:..... 0.933860752823\n",
    "\n",
    "\n",
    "Test results:\n",
    "User mean RMSE:...... 1.03549268243\n",
    "User mean MAE:....... 1.02767187417\n",
    "Item mean RMSE:...... 0.979458646244\n",
    "Item mean MAE:....... 0.974217433147\n",
    "Global mean RMSE:.... 1.11710198981\n",
    "Global mean MAE:..... 0.93386130485\n",
    "\n",
    "Linear Regression results:\n",
    "alpha:.............. 0.7818509582241939\n",
    "beta:............... 0.8748595533670936\n",
    "gamma:.............. -2.3520510519663214\n",
    "\n",
    "Train set:\n",
    "RMSE:............... 0.91462036644\n",
    "MAE:................ 0.836530516689\n",
    "Test set:\n",
    "RMSE:............... 0.924407363516\n",
    "MAE:................ 0.854531144446\n",
    "\n",
    "The RMSE is highest for the simplest approach, using the Global Mean and, following a decreasing trend, is lowest for the linear regression approach. This makes sense becuase the linear regression model makes an effort to minimize when fitting the data so that results in a lower RSME and slightly higer MAE becuase the model was not designed to minimize the overall amount of error which is what the MAE measures. It is also pretty clear that the User mean is a much worse way model then the item mean so the user bias is less significant. Since the MAE is lower then the RSME in every case there are probably abnormally large errors for a few data pairs that get minimized when finding the average error. \n",
    "\n",
    "We expected the test error to be higher then the training error due to the fact that the test set has data that the algorithm has not encountered yet. So this is not unusual\n",
    "\n",
    "Our results match those of http://mymedialite.net/examples/datasets.html \n",
    "\n",
    "# Computational Costs\n",
    "In terms of memory and time required for this approach it can be broken down into the four approaches\n",
    "\n",
    "User Mean: The time scales with the number of ratings O(N) with N being the number of ratings. The memory required is O(1) for a single calculation for one user so the total memory O(U) with U being the number of users.\n",
    "\n",
    "Item Mean: It is similar to the user mean in that for the total time it is O(N) and for the memory required it is O(1) for each calculation but total is O(I) where I is the number of items or in our case movies.\n",
    "\n",
    "Global Mean: The memory required is O(1) for the single calculatoin. The time is again O(N).\n",
    "\n",
    "Linear Regression: \n",
    "This requires O(R) memory and O(R) time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
